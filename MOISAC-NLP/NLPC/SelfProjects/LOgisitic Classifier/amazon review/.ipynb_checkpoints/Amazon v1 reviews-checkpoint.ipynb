{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:02:42.704605Z",
     "start_time": "2020-10-04T02:02:41.162079Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import nltk \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import re \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.model_selection \n",
    "import sklearn.preprocessing as preproc\n",
    "from sklearn.feature_extraction import text\n",
    "import pickle \n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset and Inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:10:31.986971Z",
     "start_time": "2020-10-04T02:10:28.019359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId                      ProfileName  \\\n",
       "Id                                                                \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "3   B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "4   B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "5   B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "Id                                                                    \n",
       "1                      1                       1      5  1303862400   \n",
       "2                      0                       0      1  1346976000   \n",
       "3                      1                       1      4  1219017600   \n",
       "4                      3                       3      2  1307923200   \n",
       "5                      0                       0      5  1350777600   \n",
       "\n",
       "                  Summary                                               Text  \n",
       "Id                                                                            \n",
       "1   Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "2       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "3   \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "4          Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "5             Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./Reviews.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:10:49.950384Z",
     "start_time": "2020-10-04T02:10:49.940328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:10:59.437952Z",
     "start_time": "2020-10-04T02:10:59.419945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId ProfileName  HelpfulnessNumerator  \\\n",
       "Id                                                                 \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW  delmartian                     1   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK      dll pa                     0   \n",
       "\n",
       "    HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "Id                                                                     \n",
       "1                        1      5  1303862400  Good Quality Dog Food   \n",
       "2                        0      1  1346976000      Not as Advertised   \n",
       "\n",
       "                                                 Text  \n",
       "Id                                                     \n",
       "1   I have bought several of the Vitality canned d...  \n",
       "2   Product arrived labeled as Jumbo Salted Peanut...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "- Deduplication : Removing the duplicate rows, which share the same UserID, ProfileName, Time & Text \n",
    "- my understanding is same person can't give two reviews at very same time for very same product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:14:30.426515Z",
     "start_time": "2020-10-04T02:14:29.103278Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.drop_duplicates(subset={'UserId', 'ProfileName', 'Time', 'Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:14:33.702951Z",
     "start_time": "2020-10-04T02:14:33.694354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393919, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring the score('STARS') given by the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:16:25.693133Z",
     "start_time": "2020-10-04T02:16:25.426943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df['Score'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- most of the user has given 5 start .. looks like imbalance dataset \n",
    "- so here I will take 5 star as Positive and rest of them as negative \n",
    "- It's all testing purpose so choosing 5 only as positive is kinda biased but I can change it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:18:45.641342Z",
     "start_time": "2020-10-04T02:18:45.573724Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Label']=0\n",
    "df.loc[df['Score']>4, ['Label']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:19:07.046124Z",
     "start_time": "2020-10-04T02:19:06.980246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6370725961428618"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['Label'] == 1])/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- so now 63 prcnt of the dataset has positive and 37% is negative \n",
    "- this doesn't look imbalance now "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text PreProcessing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:20:46.946384Z",
     "start_time": "2020-10-04T02:20:46.930042Z"
    }
   },
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:40:22.232361Z",
     "start_time": "2020-10-04T02:40:22.216303Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords= True):\n",
    "    \"\"\"\n",
    "    This function will remove unwanted character, stopwords & format the text\n",
    "    to create fewer nulls word embeddings\n",
    "    \n",
    "    \"\"\"\n",
    "    # convert words to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # replace the contractions with their longer forms \n",
    "    \n",
    "    if True: \n",
    "        text = text.split()\n",
    "        new_text =[]\n",
    "        for word in text:\n",
    "            if word in contractions: \n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "        \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # removing stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words('english'))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "     \n",
    "    #Tokenize each word    \n",
    "    text = nltk.WordPunctTokenizer().tokenize(text)\n",
    "    \n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:42:30.498130Z",
     "start_time": "2020-10-04T02:40:22.659664Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Text_cleaned'] = list(map(clean_text, df.Text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:44:02.573480Z",
     "start_time": "2020-10-04T02:42:30.501425Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatized_words(text):\n",
    "    lemm = nltk.stem.WordNetLemmatizer()\n",
    "    df['lemmatized_text'] = list(map(lambda word:\n",
    "                                     list(map(lemm.lemmatize, word)),\n",
    "                                     df.Text_cleaned))\n",
    "    \n",
    "\n",
    "lemmatized_words(df.Text_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:44:02.619656Z",
     "start_time": "2020-10-04T02:44:02.577373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text_cleaned</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "      <td>[bought, several, vitality, canned, dog, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "      <td>[product, arrived, labeled, jumbo, salted, pea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>0</td>\n",
       "      <td>[confection, around, centuries, light, pillowy...</td>\n",
       "      <td>[confection, around, century, light, pillowy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId                      ProfileName  \\\n",
       "Id                                                                \n",
       "1   B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "2   B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "3   B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "\n",
       "    HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "Id                                                                    \n",
       "1                      1                       1      5  1303862400   \n",
       "2                      0                       0      1  1346976000   \n",
       "3                      1                       1      4  1219017600   \n",
       "\n",
       "                  Summary                                               Text  \\\n",
       "Id                                                                             \n",
       "1   Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "2       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "3   \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "\n",
       "    Label                                       Text_cleaned  \\\n",
       "Id                                                             \n",
       "1       1  [bought, several, vitality, canned, dog, food,...   \n",
       "2       0  [product, arrived, labeled, jumbo, salted, pea...   \n",
       "3       0  [confection, around, centuries, light, pillowy...   \n",
       "\n",
       "                                      lemmatized_text  \n",
       "Id                                                     \n",
       "1   [bought, several, vitality, canned, dog, food,...  \n",
       "2   [product, arrived, labeled, jumbo, salted, pea...  \n",
       "3   [confection, around, century, light, pillowy, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:45:52.433345Z",
     "start_time": "2020-10-04T02:45:52.209832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "      <th>Text_cleaned</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42651</th>\n",
       "      <td>1</td>\n",
       "      <td>Had high hopes for these, but alas, these bulbs feature that unnatural, too-blue, fluorescent quality of light we all hate so much in CFL bulbs.  They take a while to \"warm\" up, but the final light is far from \"warm.\"  Good for garages, basements, and closets only.</td>\n",
       "      <td>0</td>\n",
       "      <td>[high, hopes, alas, bulbs, feature, unnatural, blue, fluorescent, quality, light, hate, much, cfl, bulbs, take, warm, final, light, far, warm, good, garages, basements, closets]</td>\n",
       "      <td>[high, hope, ala, bulb, feature, unnatural, blue, fluorescent, quality, light, hate, much, cfl, bulb, take, warm, final, light, far, warm, good, garage, basement, closet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302146</th>\n",
       "      <td>3</td>\n",
       "      <td>This is a sweet cereal, almost too sweet. Could use some protein like almonds and flax seed.</td>\n",
       "      <td>0</td>\n",
       "      <td>[sweet, cereal, almost, sweet, could, use, protein, like, almonds, flax, seed]</td>\n",
       "      <td>[sweet, cereal, almost, sweet, could, use, protein, like, almond, flax, seed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137241</th>\n",
       "      <td>4</td>\n",
       "      <td>I am generally a Seattle's Best coffee fan, but this competes well and is a bargain compared to some higher priced brands. The first bag impressed me with really oily fresh beans. The smell was somewhat off-putting when opening the bag for the first sniff. However the first batch through my French press was delicious! Upon sharing this with a few colleagues at work, the opinions were favorable. We like our coffee dark &amp; strong with no acidity. Cafe Altura French roast is a winner and will al...</td>\n",
       "      <td>0</td>\n",
       "      <td>[generally, seattle, best, coffee, fan, competes, well, bargain, compared, higher, priced, brands, first, bag, impressed, really, oily, fresh, beans, smell, somewhat, putting, opening, bag, first, sniff, however, first, batch, french, press, delicious, upon, sharing, colleagues, work, opinions, favorable, like, coffee, dark, strong, acidity, cafe, altura, french, roast, winner, also, produce, fine, espresso, stout, iced, coffee, okay, update, upon, trying, espresso, grind, coffee, still, tas...</td>\n",
       "      <td>[generally, seattle, best, coffee, fan, competes, well, bargain, compared, higher, priced, brand, first, bag, impressed, really, oily, fresh, bean, smell, somewhat, putting, opening, bag, first, sniff, however, first, batch, french, press, delicious, upon, sharing, colleague, work, opinion, favorable, like, coffee, dark, strong, acidity, cafe, altura, french, roast, winner, also, produce, fine, espresso, stout, iced, coffee, okay, update, upon, trying, espresso, grind, coffee, still, tasty, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Score  \\\n",
       "Id              \n",
       "42651       1   \n",
       "302146      3   \n",
       "137241      4   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Text  \\\n",
       "Id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "42651                                                                                                                                                                                                                                             Had high hopes for these, but alas, these bulbs feature that unnatural, too-blue, fluorescent quality of light we all hate so much in CFL bulbs.  They take a while to \"warm\" up, but the final light is far from \"warm.\"  Good for garages, basements, and closets only.   \n",
       "302146                                                                                                                                                                                                                                                                                                                                                                                                                         This is a sweet cereal, almost too sweet. Could use some protein like almonds and flax seed.   \n",
       "137241  I am generally a Seattle's Best coffee fan, but this competes well and is a bargain compared to some higher priced brands. The first bag impressed me with really oily fresh beans. The smell was somewhat off-putting when opening the bag for the first sniff. However the first batch through my French press was delicious! Upon sharing this with a few colleagues at work, the opinions were favorable. We like our coffee dark & strong with no acidity. Cafe Altura French roast is a winner and will al...   \n",
       "\n",
       "        Label  \\\n",
       "Id              \n",
       "42651       0   \n",
       "302146      0   \n",
       "137241      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Text_cleaned  \\\n",
       "Id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "42651                                                                                                                                                                                                                                                                                                                                     [high, hopes, alas, bulbs, feature, unnatural, blue, fluorescent, quality, light, hate, much, cfl, bulbs, take, warm, final, light, far, warm, good, garages, basements, closets]   \n",
       "302146                                                                                                                                                                                                                                                                                                                                                                                                                                       [sweet, cereal, almost, sweet, could, use, protein, like, almonds, flax, seed]   \n",
       "137241  [generally, seattle, best, coffee, fan, competes, well, bargain, compared, higher, priced, brands, first, bag, impressed, really, oily, fresh, beans, smell, somewhat, putting, opening, bag, first, sniff, however, first, batch, french, press, delicious, upon, sharing, colleagues, work, opinions, favorable, like, coffee, dark, strong, acidity, cafe, altura, french, roast, winner, also, produce, fine, espresso, stout, iced, coffee, okay, update, upon, trying, espresso, grind, coffee, still, tas...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            lemmatized_text  \n",
       "Id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "42651                                                                                                                                                                                                                                                                                                                                            [high, hope, ala, bulb, feature, unnatural, blue, fluorescent, quality, light, hate, much, cfl, bulb, take, warm, final, light, far, warm, good, garage, basement, closet]  \n",
       "302146                                                                                                                                                                                                                                                                                                                                                                                                                                        [sweet, cereal, almost, sweet, could, use, protein, like, almond, flax, seed]  \n",
       "137241  [generally, seattle, best, coffee, fan, competes, well, bargain, compared, higher, priced, brand, first, bag, impressed, really, oily, fresh, bean, smell, somewhat, putting, opening, bag, first, sniff, however, first, batch, french, press, delicious, upon, sharing, colleague, work, opinion, favorable, like, coffee, dark, strong, acidity, cafe, altura, french, roast, winner, also, produce, fine, espresso, stout, iced, coffee, okay, update, upon, trying, espresso, grind, coffee, still, tasty, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 500)\n",
    "df[['Score', 'Text', 'Label', 'Text_cleaned', 'lemmatized_text']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:49:20.697508Z",
     "start_time": "2020-10-04T02:49:10.288514Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110422"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_converter = CountVectorizer(tokenizer= lambda doc : doc, lowercase=False)\n",
    "x = bow_converter.fit_transform(df['Text_cleaned'])\n",
    "\n",
    "words = bow_converter.get_feature_names()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T02:52:19.038802Z",
     "start_time": "2020-10-04T02:51:20.388773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4189343"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_converter = CountVectorizer(tokenizer= lambda doc: doc, ngram_range=[2, 2], lowercase=False)\n",
    "x2 = bigram_converter.fit_transform(df['Text_cleaned'])\n",
    "bigrams = bigram_converter.get_feature_names()\n",
    "len(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:27:57.805322Z",
     "start_time": "2020-10-04T03:27:54.947312Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data, test_data = sklearn.model_selection.train_test_split(df, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:27:57.817315Z",
     "start_time": "2020-10-04T03:27:57.809379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275743, 12)\n",
      "(118176, 12)\n"
     ]
    }
   ],
   "source": [
    "print(training_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:27:57.865126Z",
     "start_time": "2020-10-04T03:27:57.848105Z"
    }
   },
   "outputs": [],
   "source": [
    "bow_transform = CountVectorizer(tokenizer=lambda doc: doc, ngram_range=[3, 3], lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:29:09.722472Z",
     "start_time": "2020-10-04T03:27:57.878415Z"
    }
   },
   "outputs": [],
   "source": [
    "X_tr_bow = bow_transform.fit_transform(training_data['Text_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:29:09.749600Z",
     "start_time": "2020-10-04T03:29:09.729946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8381115"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_transform.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:29:09.833129Z",
     "start_time": "2020-10-04T03:29:09.784780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275743, 8381115)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_bow.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:31:23.385775Z",
     "start_time": "2020-10-04T03:31:15.975380Z"
    }
   },
   "outputs": [],
   "source": [
    "X_te_bow = bow_transform.transform(test_data['Text_cleaned'])\n",
    "\n",
    "y_tr = training_data['Label']\n",
    "y_te = test_data['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-IDF transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:31:31.659881Z",
     "start_time": "2020-10-04T03:31:23.390102Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_transform = text.TfidfTransformer(norm=None)\n",
    "X_tr_tfidf = tfidf_transform.fit_transform(X_tr_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:31:33.306568Z",
     "start_time": "2020-10-04T03:31:31.663773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275743, 8381115) (275743,) (118176, 8381115) (118176,)\n"
     ]
    }
   ],
   "source": [
    "X_te_tfidf = tfidf_transform.fit_transform(X_te_bow)\n",
    "print(X_tr_bow.shape, y_tr.shape, X_te_bow.shape, y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:31:35.718130Z",
     "start_time": "2020-10-04T03:31:35.706313Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description, _C=1.0):\n",
    "    model = LogisticRegression(C =_C).fit(X_tr, y_tr)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:36:37.282865Z",
     "start_time": "2020-10-04T03:31:36.356328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with bow features 0.7184369076631465\n",
      "Test Score with tf-idf features 0.7300382480368264\n"
     ]
    }
   ],
   "source": [
    "model_bow = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "model_tfidf = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vanilla logistic regression was giving 70 % of accuracy let's use grid search Cv \n",
    "- hyperparameter tuning helps to set the hype-parameter correctly which results in better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T03:39:51.517562Z",
     "start_time": "2020-10-04T03:39:51.484186Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid_ = {'C': [1e-5, 1e-3, 1e-1, 1e0, 1e1, 1e2]}\n",
    "bow_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5, param_grid=param_grid_)\n",
    "tfidf_search = sklearn.model_selection.GridSearchCV(LogisticRegression(), cv=5,\n",
    "                                   param_grid=param_grid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T04:33:34.653030Z",
     "start_time": "2020-10-04T03:40:04.921079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [1e-05, 0.001, 0.1, 1.0, 10.0, 100.0]})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_search.fit(X_tr_bow, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T04:33:34.682460Z",
     "start_time": "2020-10-04T04:33:34.658349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7251027297008072"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T05:17:11.703415Z",
     "start_time": "2020-10-04T05:17:11.697948Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T05:17:12.158224Z",
     "start_time": "2020-10-04T05:17:12.151821Z"
    }
   },
   "outputs": [],
   "source": [
    "def naiv(X_train, y_train, X_test, y_test, description):\n",
    "    model =  MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Test Score with', description, 'features', score)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-04T05:17:14.387675Z",
     "start_time": "2020-10-04T05:17:12.380378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score with TFIDF features 0.7321791226645004\n",
      "Test Score with BOW features 0.7536047928513404\n"
     ]
    }
   ],
   "source": [
    "naiv(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'TFIDF')\n",
    "naiv(X_tr_bow, y_tr, X_te_bow, y_te, 'BOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
